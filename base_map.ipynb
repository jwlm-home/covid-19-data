{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from imageio import mimwrite\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes_data = pd.read_csv('~/nytimes/covid-19-data/us-counties.csv')\n",
    "\n",
    "nytimes_data = nytimes_data.iloc[np.where(np.isfinite(nytimes_data[['fips']].values))[0]]\n",
    "\n",
    "nytimes_data['predecessor_date'] = (\n",
    "    [date.fromisoformat(x).toordinal() - 1 for x in nytimes_data['date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210334, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nytimes_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From US Census Bureau records\n",
    "county_reader = cartopy.io.shapereader.Reader('./cb_2018_us_county_500k.shp')\n",
    "counties = list(county_reader.records())\n",
    "county_indices = pd.DataFrame({\n",
    "    'GEOID' : [float(counties[i].attributes['GEOID']) for i in range(len(counties))],\n",
    "    'index' : [i for i in range(len(counties))]})\n",
    "\n",
    "road_reader = cartopy.io.shapereader.Reader('./tl_2019_us_primaryroads.shp')\n",
    "roads = list(road_reader.records())\n",
    "\n",
    "interstates = [\n",
    "    road for road in roads if (road.attributes['RTTYP'] == 'I')]\n",
    "interstate_names = np.unique([(road.attributes['FULLNAME']) \n",
    "                              for road in interstates])\n",
    "\n",
    "interstates_by_name = (\n",
    "    {name : \n",
    "     [road.geometry \n",
    "      for road in roads\n",
    "      if road.attributes['FULLNAME'] == name]\n",
    "     for name in interstate_names})\n",
    "\n",
    "county_contents = {}\n",
    "\n",
    "for county in counties:\n",
    "    county_GEOID = int(county.attributes['GEOID'])\n",
    "    \n",
    "    intersecting_interstates = [\n",
    "        interstate_name\n",
    "        for interstate_name in interstate_names\n",
    "        if any(\n",
    "            segment_geometry\n",
    "            for segment_geometry in interstates_by_name[interstate_name]\n",
    "            if segment_geometry.intersects(county.geometry)\n",
    "\n",
    "        )]\n",
    "    \n",
    "    if len(intersecting_interstates) > 0:\n",
    "        county_contents[county_GEOID] = intersecting_interstates\n",
    "\n",
    "interstate_contents = {}\n",
    "\n",
    "for interstate_name in interstates_by_name:\n",
    "    interstate_segments = interstates_by_name[interstate_name]\n",
    "\n",
    "    intersecting_counties = [\n",
    "        int(county.attributes['GEOID'])\n",
    "        for county in counties\n",
    "        if any(\n",
    "            segment_geometry\n",
    "            for segment_geometry in interstate_segments\n",
    "            if segment_geometry.intersects(county.geometry))]\n",
    "    \n",
    "    interstate_contents[interstate_name] = intersecting_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_interstate_counts(date):\n",
    "    restricted_data = nytimes_data[nytimes_data.date == date]\n",
    "\n",
    "    restricted_data.columns = ['GEOID' if x == 'fips'\n",
    "                               else x\n",
    "                               for x in restricted_data.columns]\n",
    "\n",
    "    reader = cartopy.io.shapereader.Reader('./tl_2019_us_primaryroads.shp')\n",
    "    roads = list(reader.records())\n",
    "\n",
    "    interstates = [road for road in roads if (road.attributes['RTTYP'] == 'I')]\n",
    "    interstate_names = np.unique([(road.attributes['FULLNAME']) \n",
    "                                  for road in roads \n",
    "                                  if (road.attributes['RTTYP'] == 'I')])\n",
    "\n",
    "    interstates_by_name = (\n",
    "        {name : \n",
    "         [road.geometry \n",
    "          for road in roads\n",
    "          if road.attributes['FULLNAME'] == name]\n",
    "         for name in interstate_names})\n",
    "\n",
    "    extended_interstate_keys = pd.DataFrame(\n",
    "        data={'interstate_name' : \n",
    "              np.concatenate([np.repeat(x, len(interstate_contents[x]))\n",
    "                              for x in interstate_contents]),\n",
    "              'GEOID' :\n",
    "              np.concatenate([np.array(interstate_contents[x]).astype(np.intc)\n",
    "                              for x in interstate_contents])})\n",
    "\n",
    "    interstate_county_counts = (\n",
    "        restricted_data.merge(extended_interstate_keys, on='GEOID').\n",
    "        groupby(['interstate_name']).\n",
    "        sum())\n",
    "\n",
    "    extended_county_keys = pd.DataFrame(\n",
    "        data={\n",
    "            'GEOID' :\n",
    "            np.concatenate([np.repeat(x, len(county_contents[x])).astype(np.intc)\n",
    "                            for x in county_contents]),\n",
    "            'interstate_name' :\n",
    "            np.concatenate([np.array(county_contents[x])\n",
    "                            for x in county_contents])})\n",
    "\n",
    "    county_traffic_counts = (\n",
    "        extended_county_keys.merge(interstate_county_counts, on='interstate_name').\n",
    "        groupby(['GEOID_x']).\n",
    "        sum())\n",
    "    \n",
    "    return county_traffic_counts\n",
    "\n",
    "county_traffic_counts_dict_base = {\n",
    "    date :\n",
    "    get_county_interstate_counts(date)\n",
    "    for date in np.unique(nytimes_data.date)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the inbound and outbound work travel CSV\n",
    "\n",
    "inbound_travel = pd.read_csv('./inbound.csv')\n",
    "\n",
    "reduced_inbound_travel_base = pd.DataFrame(\n",
    "    {\n",
    "        'fips' : (\n",
    "            1000 * inbound_travel['State FIPS Code'] +\n",
    "            inbound_travel['County FIPS Code']),\n",
    "        'dest_GEOID' : (\n",
    "            1000 * inbound_travel['State FIPS Code.1'] + \n",
    "            inbound_travel['County FIPS Code.1']),\n",
    "        'flow' : (\n",
    "            [int(x.replace(',', '')) \n",
    "             for x \n",
    "             in inbound_travel['Workers in Commuting Flow']])\n",
    "    }\n",
    ").groupby('dest_GEOID').sum()\n",
    "\n",
    "reduced_inbound_travel = pd.DataFrame({\n",
    "    'fips' : [int(GEOID)\n",
    "         for GEOID, row \n",
    "         in reduced_inbound_travel_base.iterrows()],\n",
    "    'flow' : [row.flow\n",
    "         for GEOID, row \n",
    "         in reduced_inbound_travel_base.iterrows()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shelter_in_place_dates_base = pd.read_csv('./state_shelter_in_place_dates.csv')\n",
    "\n",
    "state_shelter_in_place = pd.DataFrame({\n",
    "    'state' : state_shelter_in_place_dates_base['State'],\n",
    "    'shelter_date_present' : [\n",
    "        int(type(x) == str)\n",
    "        for x \n",
    "        in state_shelter_in_place_dates_base['Shelter in place']],\n",
    "    'shelter_date' : [\n",
    "        float(date.fromisoformat(x).toordinal()) if type(x) == str \n",
    "        else np.NaN \n",
    "        for x \n",
    "        in state_shelter_in_place_dates_base['Shelter in place']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_inbound_travel_counts(record_date):\n",
    "    merged_inbound_travel = (\n",
    "        reduced_inbound_travel.merge(\n",
    "            nytimes_data[nytimes_data.date == record_date], \n",
    "            on='fips'))\n",
    "    \n",
    "    county_inbound_travel_counts = (\n",
    "        merged_inbound_travel.merge(\n",
    "            state_shelter_in_place,\n",
    "            on='state',\n",
    "            how='left')\n",
    "    )\n",
    "    \n",
    "    county_inbound_travel_counts['latency_in_place'] = [\n",
    "        (date.fromisoformat(record_date).toordinal() - x)\n",
    "        if (np.isfinite(x) and\n",
    "            x <= date.fromisoformat(record_date).toordinal())\n",
    "        else -1\n",
    "        for x\n",
    "        in county_inbound_travel_counts[ 'shelter_date']]\n",
    "    \n",
    "    final_inbound_travel_counts = (\n",
    "        county_inbound_travel_counts.merge(\n",
    "            county_traffic_counts_dict_base[record_date],\n",
    "            left_on='fips',\n",
    "            right_on='GEOID_x',\n",
    "            how='left'))\n",
    "    \n",
    "    final_inbound_travel_counts['ordinal_date'] = (\n",
    "        [date.fromisoformat(record_date).toordinal()] * \n",
    "        final_inbound_travel_counts.shape[0])\n",
    "    \n",
    "    output_inbound_travel_counts = (\n",
    "        final_inbound_travel_counts.merge(\n",
    "            nytimes_data,\n",
    "            left_on=['ordinal_date', 'fips'],\n",
    "            right_on=['predecessor_date', 'fips']))\n",
    "    \n",
    "    return output_inbound_travel_counts\n",
    "\n",
    "merge_inbound_travel_counts_dict_base = {\n",
    "    date :\n",
    "    merge_inbound_travel_counts(date)\n",
    "    for date in np.unique(nytimes_data.date)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_base = pd.concat([\n",
    "    merge_inbound_travel_counts_dict_base[x] \n",
    "    for x in merge_inbound_travel_counts_dict_base])\n",
    "\n",
    "train_data_base_columns = [\n",
    "    'flow',\n",
    "    'cases_x',\n",
    "    'deaths_x',\n",
    "    'shelter_date_present',\n",
    "    'latency_in_place',\n",
    "    'cases_y',\n",
    "    'deaths_y',\n",
    "    'cases',\n",
    "    'deaths',\n",
    "    'fips',\n",
    "]\n",
    "\n",
    "all_train_data_columns = [\n",
    "    'intercounty_flow',\n",
    "    'local_cases',\n",
    "    'local_deaths',\n",
    "    'sheltering_in_place',\n",
    "    'ndays_sheltering_in_place',\n",
    "    'interstate_borne_cases',\n",
    "    'interstate_borne_deaths',\n",
    "    'target_cases',\n",
    "    'target_deaths',\n",
    "    'county_GEOID'\n",
    "]\n",
    "\n",
    "all_train_data_frame = all_train_data_base[train_data_base_columns]\n",
    "all_train_data_frame.columns = all_train_data_columns\n",
    "\n",
    "all_train_data = all_train_data_frame.values\n",
    "all_train_data[~np.isfinite(all_train_data[:, 3]), 3] = 0\n",
    "all_train_data[~np.isfinite(all_train_data[:, 5]), 5] = 0\n",
    "all_train_data[~np.isfinite(all_train_data[:, 6]), 6] = 0\n",
    "\n",
    "train_data_scaler = StandardScaler()\n",
    "all_train_data[:, :-3] = train_data_scaler.fit_transform(all_train_data[:, :-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 207348 samples\n",
      "Epoch 1/50\n",
      "207348/207348 - 11s - loss: 206.9688 - mse: 1895686.0000 - mae: 206.9687\n",
      "Epoch 2/50\n",
      "207348/207348 - 8s - loss: 55.3072 - mse: 76867.0938 - mae: 55.3072\n",
      "Epoch 3/50\n",
      "207348/207348 - 8s - loss: 33.5282 - mse: 31711.8008 - mae: 33.5282\n",
      "Epoch 4/50\n",
      "207348/207348 - 8s - loss: 13.2794 - mse: 6007.9360 - mae: 13.2794\n",
      "Epoch 5/50\n",
      "207348/207348 - 9s - loss: 5.9010 - mse: 1118.3090 - mae: 5.9010\n",
      "Epoch 6/50\n",
      "207348/207348 - 8s - loss: 5.8052 - mse: 1101.6987 - mae: 5.8052\n",
      "Epoch 7/50\n",
      "207348/207348 - 8s - loss: 5.7447 - mse: 1079.2231 - mae: 5.7447\n",
      "Epoch 8/50\n",
      "207348/207348 - 8s - loss: 5.7018 - mse: 1056.4039 - mae: 5.7018\n",
      "Epoch 9/50\n",
      "207348/207348 - 8s - loss: 5.6764 - mse: 1045.5798 - mae: 5.6764\n",
      "Epoch 10/50\n",
      "207348/207348 - 9s - loss: 5.6379 - mse: 1037.6041 - mae: 5.6379\n",
      "Epoch 11/50\n",
      "207348/207348 - 16s - loss: 5.6206 - mse: 1017.5212 - mae: 5.6206\n",
      "Epoch 12/50\n",
      "207348/207348 - 15s - loss: 5.5972 - mse: 1019.1523 - mae: 5.5972\n",
      "Epoch 13/50\n",
      "207348/207348 - 20s - loss: 5.5784 - mse: 997.6281 - mae: 5.5784\n",
      "Epoch 14/50\n",
      "207348/207348 - 14s - loss: 5.5557 - mse: 971.0024 - mae: 5.5557\n",
      "Epoch 15/50\n",
      "207348/207348 - 12s - loss: 5.5364 - mse: 962.5114 - mae: 5.5364\n",
      "Epoch 16/50\n",
      "207348/207348 - 12s - loss: 5.5282 - mse: 953.1514 - mae: 5.5282\n",
      "Epoch 17/50\n",
      "207348/207348 - 13s - loss: 5.5342 - mse: 969.6932 - mae: 5.5342\n",
      "Epoch 18/50\n",
      "207348/207348 - 14s - loss: 5.5365 - mse: 957.4318 - mae: 5.5365\n",
      "Epoch 19/50\n",
      "207348/207348 - 12s - loss: 5.5444 - mse: 962.9859 - mae: 5.5444\n",
      "Epoch 20/50\n",
      "207348/207348 - 12s - loss: 5.5350 - mse: 964.1763 - mae: 5.5350\n",
      "Epoch 21/50\n",
      "207348/207348 - 12s - loss: 5.5320 - mse: 959.3198 - mae: 5.5320\n",
      "Epoch 22/50\n",
      "207348/207348 - 12s - loss: 5.5184 - mse: 952.3398 - mae: 5.5184\n",
      "Epoch 23/50\n",
      "207348/207348 - 12s - loss: 5.5308 - mse: 964.6406 - mae: 5.5308\n",
      "Epoch 24/50\n",
      "207348/207348 - 12s - loss: 5.5353 - mse: 960.1247 - mae: 5.5353\n",
      "Epoch 25/50\n",
      "207348/207348 - 14s - loss: 5.5286 - mse: 954.6824 - mae: 5.5286\n",
      "Epoch 26/50\n",
      "207348/207348 - 12s - loss: 5.5099 - mse: 945.7998 - mae: 5.5099\n",
      "Epoch 27/50\n",
      "207348/207348 - 17s - loss: 5.5253 - mse: 951.9565 - mae: 5.5253\n",
      "Epoch 28/50\n",
      "207348/207348 - 14s - loss: 5.5202 - mse: 948.4690 - mae: 5.5202\n",
      "Epoch 29/50\n",
      "207348/207348 - 11s - loss: 5.5311 - mse: 958.3583 - mae: 5.5311\n",
      "Epoch 30/50\n",
      "207348/207348 - 13s - loss: 5.5231 - mse: 945.9738 - mae: 5.5231\n",
      "Epoch 31/50\n",
      "207348/207348 - 11s - loss: 5.5105 - mse: 941.0867 - mae: 5.5105\n",
      "Epoch 32/50\n",
      "207348/207348 - 16s - loss: 5.5245 - mse: 958.2659 - mae: 5.5245\n",
      "Epoch 33/50\n",
      "207348/207348 - 12s - loss: 5.5298 - mse: 956.2444 - mae: 5.5298\n",
      "Epoch 34/50\n",
      "207348/207348 - 12s - loss: 5.5286 - mse: 960.4067 - mae: 5.5286\n",
      "Epoch 35/50\n",
      "207348/207348 - 17s - loss: 5.5174 - mse: 961.0806 - mae: 5.5174\n",
      "Epoch 36/50\n",
      "207348/207348 - 15s - loss: 5.5261 - mse: 960.1124 - mae: 5.5261\n",
      "Epoch 37/50\n",
      "207348/207348 - 13s - loss: 5.5284 - mse: 950.7315 - mae: 5.5284\n",
      "Epoch 38/50\n",
      "207348/207348 - 15s - loss: 5.5150 - mse: 949.8056 - mae: 5.5150\n",
      "Epoch 39/50\n",
      "207348/207348 - 14s - loss: 5.5160 - mse: 951.4797 - mae: 5.5160\n",
      "Epoch 40/50\n",
      "207348/207348 - 14s - loss: 5.5120 - mse: 949.4443 - mae: 5.5120\n",
      "Epoch 41/50\n",
      "207348/207348 - 11s - loss: 5.5173 - mse: 949.4214 - mae: 5.5173\n",
      "Epoch 42/50\n",
      "207348/207348 - 12s - loss: 5.5333 - mse: 959.2354 - mae: 5.5333\n",
      "Epoch 43/50\n",
      "207348/207348 - 19s - loss: 5.5082 - mse: 943.2881 - mae: 5.5082\n",
      "Epoch 44/50\n",
      "207348/207348 - 19s - loss: 5.5086 - mse: 936.9051 - mae: 5.5086\n",
      "Epoch 45/50\n",
      "207348/207348 - 15s - loss: 5.5041 - mse: 941.2359 - mae: 5.5041\n",
      "Epoch 46/50\n",
      "207348/207348 - 15s - loss: 5.5216 - mse: 956.6785 - mae: 5.5216\n",
      "Epoch 47/50\n",
      "207348/207348 - 15s - loss: 5.5187 - mse: 946.9861 - mae: 5.5187\n",
      "Epoch 48/50\n",
      "207348/207348 - 21s - loss: 5.5076 - mse: 939.6904 - mae: 5.5076\n",
      "Epoch 49/50\n",
      "207348/207348 - 10s - loss: 5.5137 - mse: 948.6815 - mae: 5.5137\n",
      "Epoch 50/50\n",
      "207348/207348 - 12s - loss: 5.5068 - mse: 942.8087 - mae: 5.5068\n"
     ]
    }
   ],
   "source": [
    "predictor_input = tf.keras.Input(shape=(all_train_data.shape[1] - 3,), )\n",
    "predictor_inner = tf.keras.layers.Dense(10, activation='relu')(predictor_input)\n",
    "predictor_inner = tf.keras.layers.Dense(10, activation='relu')(predictor_inner)\n",
    "predictor_output = tf.keras.layers.Dense(1, activation='linear')(predictor_inner)\n",
    "\n",
    "predictor_model = tf.keras.Model(inputs=predictor_input, outputs=predictor_output)\n",
    "predictor_model.summary()\n",
    "\n",
    "predictor_model.compile(tf.keras.optimizers.Nadam(lr=1e-3), \n",
    "                        loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                        metrics=['mse', 'mae'],\n",
    "                       )\n",
    "\n",
    "predictor_history = predictor_model.fit(\n",
    "    all_train_data[:, :-3], \n",
    "    all_train_data[:, -3],\n",
    "    epochs=50,\n",
    "    verbose=2,\n",
    "    batch_size=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictor_model.predict(all_train_data[:, :-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(\n",
    "    np.hstack([results, \n",
    "               np.array(all_train_data[:, -3]).reshape(-1, 1),\n",
    "               np.array(all_train_data[:, -1]).reshape(-1, 1), \n",
    "               all_train_data_base['ordinal_date'].values.reshape(-1, 1)\n",
    "              ]))\n",
    "y.columns = ['predicted_count', 'actual_count', 'GEOID', 'ordinal_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_county_cases(result_array, date_string):\n",
    "    restricted_result_array = pd.DataFrame(\n",
    "        result_array.loc()[\n",
    "            date.fromisoformat(date_string).toordinal() == result_array.iloc()[:, 3],\n",
    "            :]).merge(county_indices).values\n",
    "    \n",
    "    central_lat = 37.5\n",
    "    central_lon = -96\n",
    "    extent = [-120, -70, 23, 50.5]\n",
    "    central_lon = np.mean(extent[:2])\n",
    "    central_lat = np.mean(extent[2:])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax = plt.axes(projection=ccrs.AlbersEqualArea(central_lon, central_lat))\n",
    "    ax.set_extent(extent)\n",
    "\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    ax.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.LAKES, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.BORDERS)\n",
    "    ax.add_feature(\n",
    "        cartopy.feature.ShapelyFeature(\n",
    "            [counties[int(restricted_result_array[int(i), -1])].geometry \n",
    "             for i in range(restricted_result_array.shape[0])], \n",
    "            cartopy.crs.PlateCarree(),\n",
    "            color='pink'))\n",
    "\n",
    "    ax.add_feature(cartopy.feature.STATES, edgecolor='lightgrey')\n",
    "    ax.add_feature(\n",
    "        cartopy.feature.ShapelyFeature(\n",
    "            [interstate.geometry for interstate in interstates],\n",
    "            cartopy.crs.PlateCarree(),\n",
    "            color='grey'))\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return image\n",
    "\n",
    "county_cases = [\n",
    "    plot_county_cases(y, image_date) \n",
    "    for image_date in np.unique(nytimes_data.date)[:-1]\n",
    "]\n",
    "\n",
    "mimwrite('./county_cases.gif', \n",
    "         county_cases,\n",
    "         fps=5,\n",
    "         subrectangles=True,\n",
    "         loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_county_counts(result_array, date_string):\n",
    "    restricted_result_array = pd.DataFrame(\n",
    "        result_array.loc()[\n",
    "            date.fromisoformat(date_string).toordinal() == result_array.iloc()[:, 3],\n",
    "            :]).merge(county_indices).values\n",
    "        \n",
    "    extent = [-125, -65, 23, 50.5]\n",
    "    central_lon = np.mean(extent[:2])\n",
    "    central_lat = np.mean(extent[2:])\n",
    "    \n",
    "    main_proj = cartopy.crs.PlateCarree()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax = plt.axes(projection=ccrs.AlbersEqualArea(central_lon, central_lat))\n",
    "    ax.set_extent(extent)\n",
    "    ax.set_aspect('auto')\n",
    "\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    ax.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.LAKES, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.BORDERS)\n",
    "\n",
    "    centroids = [\n",
    "        counties[int(restricted_result_array[int(i), -1])].\n",
    "        geometry.\n",
    "        centroid.\n",
    "        xy\n",
    "        for i in range(restricted_result_array.shape[0])]\n",
    "    \n",
    "    diffs = [np.abs(restricted_result_array[int(i), 0] - restricted_result_array[int(i), 1] )\n",
    "        for i in range(restricted_result_array.shape[0])]\n",
    "\n",
    "    for (centroid, diff) in zip(centroids, diffs):\n",
    "        x, y = centroid\n",
    "        radius = diff * 0.05\n",
    "        ax.add_patch(patches.Circle(xy=[x[0], y[0]], \n",
    "                                    radius=radius,                           \n",
    "                                    color='b', \n",
    "                                    alpha=0.3, \n",
    "                                    transform=main_proj))\n",
    "\n",
    "    ax.add_feature(cartopy.feature.STATES, edgecolor='lightgrey')\n",
    "            \n",
    "    ax.add_feature(\n",
    "        cartopy.feature.ShapelyFeature(\n",
    "            [interstate.geometry for interstate in interstates],\n",
    "            cartopy.crs.PlateCarree(),\n",
    "            color='grey'))            \n",
    "            \n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    return image\n",
    "\n",
    "county_counts = [\n",
    "    plot_county_counts(y, image_date) \n",
    "    for image_date in np.unique(nytimes_data.date)[:-1]\n",
    "]\n",
    "\n",
    "mimwrite('./county_counts.gif',\n",
    "         county_counts, \n",
    "         fps=5,\n",
    "         subrectangles=True,\n",
    "         loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_county_counts(result_array, date_string):\n",
    "    restricted_result_array = pd.DataFrame(\n",
    "        result_array.loc()[\n",
    "            date.fromisoformat(date_string).toordinal() == result_array.iloc()[:, 3],\n",
    "            :]).merge(county_indices).values\n",
    "        \n",
    "    extent = [-125, -65, 23, 50.5]\n",
    "    central_lon = np.mean(extent[:2])\n",
    "    central_lat = np.mean(extent[2:])\n",
    "    \n",
    "    main_proj = cartopy.crs.PlateCarree()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax = plt.axes(projection=ccrs.AlbersEqualArea(central_lon, central_lat))\n",
    "    ax.set_extent(extent)\n",
    "    ax.set_aspect('auto')\n",
    "\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    ax.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.LAKES, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.BORDERS)\n",
    "\n",
    "    centroids = [\n",
    "        counties[int(restricted_result_array[int(i), -1])].\n",
    "        geometry.\n",
    "        centroid.\n",
    "        xy\n",
    "        for i in range(restricted_result_array.shape[0])]\n",
    "    \n",
    "    counts = [restricted_result_array[int(i), 1]\n",
    "        for i in range(restricted_result_array.shape[0])]\n",
    "\n",
    "    for (centroid, count) in zip(centroids, counts):\n",
    "        x, y = centroid\n",
    "        radius = count * 0.05\n",
    "        ax.add_patch(patches.Circle(xy=[x[0], y[0]], \n",
    "                                    radius=radius,                           \n",
    "                                    color='b', \n",
    "                                    alpha=0.3, \n",
    "                                    transform=main_proj))\n",
    "\n",
    "    ax.add_feature(cartopy.feature.STATES, edgecolor='lightgrey')\n",
    "            \n",
    "    ax.add_feature(\n",
    "        cartopy.feature.ShapelyFeature(\n",
    "            [interstate.geometry for interstate in interstates],\n",
    "            cartopy.crs.PlateCarree(),\n",
    "            color='grey'))            \n",
    "            \n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    return image\n",
    "\n",
    "county_counts = [\n",
    "    plot_county_counts(y, image_date) \n",
    "    for image_date in np.unique(nytimes_data.date)[:-1]\n",
    "]\n",
    "\n",
    "mimwrite('./county_counts.gif',\n",
    "         county_counts, \n",
    "         fps=5,\n",
    "         subrectangles=True,\n",
    "         loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
