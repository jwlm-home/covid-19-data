{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROJ: proj_create_from_database: Cannot find proj.db\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from imageio import mimwrite\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes_data = pd.read_csv('./us-counties.csv')\n",
    "\n",
    "nytimes_data = nytimes_data.iloc[np.where(np.isfinite(nytimes_data[['fips']].values))[0]]\n",
    "\n",
    "nytimes_data['predecessor_date'] = (\n",
    "    [date.fromisoformat(x).toordinal() - 1 for x in nytimes_data['date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From US Census Bureau records\n",
    "county_reader = cartopy.io.shapereader.Reader('./cb_2018_us_county_500k/cb_2018_us_county_500k.shp')\n",
    "counties = list(county_reader.records())\n",
    "county_indices = pd.DataFrame({\n",
    "    'GEOID' : [float(counties[i].attributes['GEOID']) for i in range(len(counties))],\n",
    "    'index' : [i for i in range(len(counties))]})\n",
    "\n",
    "road_reader = cartopy.io.shapereader.Reader('./tl_2019_us_primaryroads/tl_2019_us_primaryroads.shp')\n",
    "roads = list(road_reader.records())\n",
    "\n",
    "interstates = [\n",
    "    road for road in roads if (road.attributes['RTTYP'] == 'I')]\n",
    "interstate_names = np.unique([(road.attributes['FULLNAME']) \n",
    "                              for road in interstates])\n",
    "\n",
    "interstates_by_name = (\n",
    "    {name : \n",
    "     [road.geometry \n",
    "      for road in roads\n",
    "      if road.attributes['FULLNAME'] == name]\n",
    "     for name in interstate_names})\n",
    "\n",
    "county_contents = {}\n",
    "\n",
    "for county in counties:\n",
    "    county_GEOID = int(county.attributes['GEOID'])\n",
    "    \n",
    "    intersecting_interstates = [\n",
    "        interstate_name\n",
    "        for interstate_name in interstate_names\n",
    "        if any(\n",
    "            segment_geometry\n",
    "            for segment_geometry in interstates_by_name[interstate_name]\n",
    "            if segment_geometry.intersects(county.geometry)\n",
    "\n",
    "        )]\n",
    "    \n",
    "    if len(intersecting_interstates) > 0:\n",
    "        county_contents[county_GEOID] = intersecting_interstates\n",
    "\n",
    "interstate_contents = {}\n",
    "\n",
    "for interstate_name in interstates_by_name:\n",
    "    interstate_segments = interstates_by_name[interstate_name]\n",
    "\n",
    "    intersecting_counties = [\n",
    "        int(county.attributes['GEOID'])\n",
    "        for county in counties\n",
    "        if any(\n",
    "            segment_geometry\n",
    "            for segment_geometry in interstate_segments\n",
    "            if segment_geometry.intersects(county.geometry))]\n",
    "    \n",
    "    interstate_contents[interstate_name] = intersecting_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_county_interstate_counts(date):\n",
    "    restricted_data = nytimes_data[nytimes_data.date == date]\n",
    "\n",
    "    restricted_data.columns = ['GEOID' if x == 'fips'\n",
    "                               else x\n",
    "                               for x in restricted_data.columns]\n",
    "\n",
    "    reader = cartopy.io.shapereader.Reader('./tl_2019_us_primaryroads/tl_2019_us_primaryroads.shp')\n",
    "    roads = list(reader.records())\n",
    "\n",
    "    interstates = [road for road in roads if (road.attributes['RTTYP'] == 'I')]\n",
    "    interstate_names = np.unique([(road.attributes['FULLNAME']) \n",
    "                                  for road in roads \n",
    "                                  if (road.attributes['RTTYP'] == 'I')])\n",
    "\n",
    "    interstates_by_name = (\n",
    "        {name : \n",
    "         [road.geometry \n",
    "          for road in roads\n",
    "          if road.attributes['FULLNAME'] == name]\n",
    "         for name in interstate_names})\n",
    "\n",
    "    extended_interstate_keys = pd.DataFrame(\n",
    "        data={'interstate_name' : \n",
    "              np.concatenate([np.repeat(x, len(interstate_contents[x]))\n",
    "                              for x in interstate_contents]),\n",
    "              'GEOID' :\n",
    "              np.concatenate([np.array(interstate_contents[x]).astype(np.intc)\n",
    "                              for x in interstate_contents])})\n",
    "\n",
    "    interstate_county_counts = (\n",
    "        restricted_data.merge(extended_interstate_keys, on='GEOID').\n",
    "        groupby(['interstate_name']).\n",
    "        sum())\n",
    "\n",
    "    extended_county_keys = pd.DataFrame(\n",
    "        data={\n",
    "            'GEOID' :\n",
    "            np.concatenate([np.repeat(x, len(county_contents[x])).astype(np.intc)\n",
    "                            for x in county_contents]),\n",
    "            'interstate_name' :\n",
    "            np.concatenate([np.array(county_contents[x])\n",
    "                            for x in county_contents])})\n",
    "\n",
    "    county_traffic_counts = (\n",
    "        extended_county_keys.merge(interstate_county_counts, on='interstate_name').\n",
    "        groupby(['GEOID_x']).\n",
    "        sum())\n",
    "    \n",
    "    return county_traffic_counts\n",
    "\n",
    "county_traffic_counts_dict_base = {\n",
    "    date :\n",
    "    get_county_interstate_counts(date)\n",
    "    for date in np.unique(nytimes_data.date)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the inbound and outbound work travel CSV\n",
    "\n",
    "inbound_travel = pd.read_csv('./inbound.csv')\n",
    "\n",
    "reduced_inbound_travel_base = pd.DataFrame(\n",
    "    {\n",
    "        'fips' : (\n",
    "            1000 * inbound_travel['State FIPS Code'] +\n",
    "            inbound_travel['County FIPS Code']),\n",
    "        'dest_GEOID' : (\n",
    "            1000 * inbound_travel['State FIPS Code.1'] + \n",
    "            inbound_travel['County FIPS Code.1']),\n",
    "        'flow' : (\n",
    "            [int(x.replace(',', '')) \n",
    "             for x \n",
    "             in inbound_travel['Workers in Commuting Flow']])\n",
    "    }\n",
    ").groupby('dest_GEOID').sum()\n",
    "\n",
    "reduced_inbound_travel = pd.DataFrame({\n",
    "    'fips' : [int(GEOID)\n",
    "         for GEOID, row \n",
    "         in reduced_inbound_travel_base.iterrows()],\n",
    "    'flow' : [row.flow\n",
    "         for GEOID, row \n",
    "         in reduced_inbound_travel_base.iterrows()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shelter_in_place_dates_base = pd.read_csv('./state_shelter_in_place_dates.csv')\n",
    "\n",
    "state_shelter_in_place = pd.DataFrame({\n",
    "    'state' : state_shelter_in_place_dates_base['State'],\n",
    "    'shelter_date_present' : [\n",
    "        int(type(x) == str)\n",
    "        for x \n",
    "        in state_shelter_in_place_dates_base['Shelter in place']],\n",
    "    'shelter_date' : [\n",
    "        float(date.fromisoformat(x).toordinal()) if type(x) == str \n",
    "        else np.NaN \n",
    "        for x \n",
    "        in state_shelter_in_place_dates_base['Shelter in place']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_inbound_travel_counts(record_date):\n",
    "    merged_inbound_travel = (\n",
    "        reduced_inbound_travel.merge(\n",
    "            nytimes_data[nytimes_data.date == record_date], \n",
    "            on='fips'))\n",
    "    \n",
    "    county_inbound_travel_counts = (\n",
    "        merged_inbound_travel.merge(\n",
    "            state_shelter_in_place,\n",
    "            on='state',\n",
    "            how='left')\n",
    "    )\n",
    "    \n",
    "    county_inbound_travel_counts['latency_in_place'] = [\n",
    "        (date.fromisoformat(record_date).toordinal() - x)\n",
    "        if (np.isfinite(x) and\n",
    "            x <= date.fromisoformat(record_date).toordinal())\n",
    "        else -1\n",
    "        for x\n",
    "        in county_inbound_travel_counts[ 'shelter_date']]\n",
    "    \n",
    "    final_inbound_travel_counts = (\n",
    "        county_inbound_travel_counts.merge(\n",
    "            county_traffic_counts_dict_base[record_date],\n",
    "            left_on='fips',\n",
    "            right_on='GEOID_x',\n",
    "            how='left'))\n",
    "    \n",
    "    final_inbound_travel_counts['ordinal_date'] = (\n",
    "        [date.fromisoformat(record_date).toordinal()] * \n",
    "        final_inbound_travel_counts.shape[0])\n",
    "    \n",
    "    output_inbound_travel_counts = (\n",
    "        final_inbound_travel_counts.merge(\n",
    "            nytimes_data,\n",
    "            left_on=['ordinal_date', 'fips'],\n",
    "            right_on=['predecessor_date', 'fips']))\n",
    "    \n",
    "    return output_inbound_travel_counts\n",
    "\n",
    "merge_inbound_travel_counts_dict_base = {\n",
    "    date :\n",
    "    merge_inbound_travel_counts(date)\n",
    "    for date in np.unique(nytimes_data.date)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_base = pd.concat([\n",
    "    merge_inbound_travel_counts_dict_base[x] \n",
    "    for x in merge_inbound_travel_counts_dict_base])\n",
    "\n",
    "train_data_base_columns = [\n",
    "    'flow',\n",
    "    'cases_x',\n",
    "    'deaths_x',\n",
    "    'shelter_date_present',\n",
    "    'latency_in_place',\n",
    "    'cases_y',\n",
    "    'deaths_y',\n",
    "    'cases',\n",
    "    'deaths',\n",
    "    'fips',\n",
    "]\n",
    "\n",
    "all_train_data_columns = [\n",
    "    'intercounty_flow',\n",
    "    'local_cases',\n",
    "    'local_deaths',\n",
    "    'sheltering_in_place',\n",
    "    'ndays_sheltering_in_place',\n",
    "    'interstate_borne_cases',\n",
    "    'interstate_borne_deaths',\n",
    "    'target_cases',\n",
    "    'target_deaths',\n",
    "    'county_GEOID'\n",
    "]\n",
    "\n",
    "all_train_data_frame = all_train_data_base[train_data_base_columns]\n",
    "all_train_data_frame.columns = all_train_data_columns\n",
    "\n",
    "all_train_data = all_train_data_frame.values\n",
    "all_train_data[~np.isfinite(all_train_data[:, 3]), 3] = 0\n",
    "all_train_data[~np.isfinite(all_train_data[:, 5]), 5] = 0\n",
    "all_train_data[~np.isfinite(all_train_data[:, 6]), 6] = 0\n",
    "\n",
    "train_data_scaler = StandardScaler()\n",
    "all_train_data[:, :-3] = train_data_scaler.fit_transform(all_train_data[:, :-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 69260 samples\n",
      "Epoch 1/50\n",
      "69260/69260 - 2s - loss: 112.2442 - mse: 622049.5625 - mae: 112.2443\n",
      "Epoch 2/50\n",
      "69260/69260 - 1s - loss: 86.5432 - mse: 391932.8750 - mae: 86.5433\n",
      "Epoch 3/50\n",
      "69260/69260 - 1s - loss: 43.2719 - mse: 88008.7969 - mae: 43.2719\n",
      "Epoch 4/50\n",
      "69260/69260 - 1s - loss: 28.2587 - mse: 31845.3320 - mae: 28.2586\n",
      "Epoch 5/50\n",
      "69260/69260 - 1s - loss: 23.7976 - mse: 24202.1074 - mae: 23.7976\n",
      "Epoch 6/50\n",
      "69260/69260 - 1s - loss: 20.1816 - mse: 18135.0605 - mae: 20.1816\n",
      "Epoch 7/50\n",
      "69260/69260 - 1s - loss: 16.4005 - mse: 12596.7432 - mae: 16.4005\n",
      "Epoch 8/50\n",
      "69260/69260 - 1s - loss: 12.6642 - mse: 8017.7466 - mae: 12.6642\n",
      "Epoch 9/50\n",
      "69260/69260 - 1s - loss: 9.2305 - mse: 4448.2334 - mae: 9.2305\n",
      "Epoch 10/50\n",
      "69260/69260 - 1s - loss: 7.0479 - mse: 2464.4116 - mae: 7.0479\n",
      "Epoch 11/50\n",
      "69260/69260 - 1s - loss: 6.2199 - mse: 1783.3760 - mae: 6.2199\n",
      "Epoch 12/50\n",
      "69260/69260 - 1s - loss: 5.9307 - mse: 1585.1995 - mae: 5.9307\n",
      "Epoch 13/50\n",
      "69260/69260 - 1s - loss: 5.7741 - mse: 1466.7563 - mae: 5.7741\n",
      "Epoch 14/50\n",
      "69260/69260 - 1s - loss: 5.6782 - mse: 1384.3562 - mae: 5.6782\n",
      "Epoch 15/50\n",
      "69260/69260 - 1s - loss: 5.6015 - mse: 1365.3516 - mae: 5.6015\n",
      "Epoch 16/50\n",
      "69260/69260 - 1s - loss: 5.5181 - mse: 1310.7595 - mae: 5.5181\n",
      "Epoch 17/50\n",
      "69260/69260 - 1s - loss: 5.4721 - mse: 1266.8099 - mae: 5.4721\n",
      "Epoch 18/50\n",
      "69260/69260 - 1s - loss: 5.4152 - mse: 1255.8118 - mae: 5.4152\n",
      "Epoch 19/50\n",
      "69260/69260 - 1s - loss: 5.3636 - mse: 1224.1754 - mae: 5.3636\n",
      "Epoch 20/50\n",
      "69260/69260 - 1s - loss: 5.3165 - mse: 1189.8707 - mae: 5.3165\n",
      "Epoch 21/50\n",
      "69260/69260 - 1s - loss: 5.2592 - mse: 1147.4388 - mae: 5.2592\n",
      "Epoch 22/50\n",
      "69260/69260 - 1s - loss: 5.2113 - mse: 1113.4574 - mae: 5.2113\n",
      "Epoch 23/50\n",
      "69260/69260 - 1s - loss: 5.1673 - mse: 1109.4070 - mae: 5.1673\n",
      "Epoch 24/50\n",
      "69260/69260 - 1s - loss: 5.1285 - mse: 1051.6101 - mae: 5.1285\n",
      "Epoch 25/50\n",
      "69260/69260 - 1s - loss: 5.0698 - mse: 1032.9761 - mae: 5.0698\n",
      "Epoch 26/50\n",
      "69260/69260 - 1s - loss: 5.0587 - mse: 1026.3934 - mae: 5.0587\n",
      "Epoch 27/50\n",
      "69260/69260 - 1s - loss: 5.0393 - mse: 987.8138 - mae: 5.0393\n",
      "Epoch 28/50\n",
      "69260/69260 - 1s - loss: 5.0122 - mse: 986.9404 - mae: 5.0122\n",
      "Epoch 29/50\n",
      "69260/69260 - 1s - loss: 4.9871 - mse: 956.4832 - mae: 4.9871\n",
      "Epoch 30/50\n",
      "69260/69260 - 1s - loss: 4.9770 - mse: 923.1149 - mae: 4.9770\n",
      "Epoch 31/50\n",
      "69260/69260 - 1s - loss: 4.9449 - mse: 910.1489 - mae: 4.9449\n",
      "Epoch 32/50\n",
      "69260/69260 - 1s - loss: 4.9380 - mse: 907.3455 - mae: 4.9380\n",
      "Epoch 33/50\n",
      "69260/69260 - 1s - loss: 4.9336 - mse: 895.9541 - mae: 4.9336\n",
      "Epoch 34/50\n",
      "69260/69260 - 1s - loss: 4.9163 - mse: 864.3301 - mae: 4.9163\n",
      "Epoch 35/50\n",
      "69260/69260 - 1s - loss: 4.8967 - mse: 855.7179 - mae: 4.8967\n",
      "Epoch 36/50\n",
      "69260/69260 - 1s - loss: 4.8649 - mse: 834.6237 - mae: 4.8649\n",
      "Epoch 37/50\n",
      "69260/69260 - 1s - loss: 4.8791 - mse: 846.8839 - mae: 4.8791\n",
      "Epoch 38/50\n",
      "69260/69260 - 1s - loss: 4.8627 - mse: 848.9482 - mae: 4.8627\n",
      "Epoch 39/50\n",
      "69260/69260 - 1s - loss: 4.8655 - mse: 843.2268 - mae: 4.8655\n",
      "Epoch 40/50\n",
      "69260/69260 - 1s - loss: 4.8635 - mse: 833.7076 - mae: 4.8635\n",
      "Epoch 41/50\n",
      "69260/69260 - 1s - loss: 4.8461 - mse: 803.4285 - mae: 4.8461\n",
      "Epoch 42/50\n",
      "69260/69260 - 1s - loss: 4.8272 - mse: 816.8914 - mae: 4.8272\n",
      "Epoch 43/50\n",
      "69260/69260 - 1s - loss: 4.8522 - mse: 815.9195 - mae: 4.8522\n",
      "Epoch 44/50\n",
      "69260/69260 - 1s - loss: 4.8386 - mse: 797.9388 - mae: 4.8386\n",
      "Epoch 45/50\n",
      "69260/69260 - 1s - loss: 4.8297 - mse: 805.2556 - mae: 4.8297\n",
      "Epoch 46/50\n",
      "69260/69260 - 1s - loss: 4.8175 - mse: 788.5691 - mae: 4.8175\n",
      "Epoch 47/50\n",
      "69260/69260 - 1s - loss: 4.8084 - mse: 788.6411 - mae: 4.8084\n",
      "Epoch 48/50\n",
      "69260/69260 - 1s - loss: 4.8090 - mse: 780.2340 - mae: 4.8090\n",
      "Epoch 49/50\n",
      "69260/69260 - 1s - loss: 4.8086 - mse: 777.0466 - mae: 4.8086\n",
      "Epoch 50/50\n",
      "69260/69260 - 1s - loss: 4.7988 - mse: 779.8135 - mae: 4.7988\n"
     ]
    }
   ],
   "source": [
    "predictor_input = tf.keras.Input(shape=(all_train_data.shape[1] - 3,), )\n",
    "predictor_inner = tf.keras.layers.Dense(10, activation='relu')(predictor_input)\n",
    "predictor_inner = tf.keras.layers.Dense(10, activation='relu')(predictor_inner)\n",
    "predictor_output = tf.keras.layers.Dense(1, activation='linear')(predictor_inner)\n",
    "\n",
    "predictor_model = tf.keras.Model(inputs=predictor_input, outputs=predictor_output)\n",
    "predictor_model.summary()\n",
    "\n",
    "predictor_model.compile(tf.keras.optimizers.Nadam(lr=1e-3), \n",
    "                        loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                        metrics=['mse', 'mae'],\n",
    "                       )\n",
    "\n",
    "predictor_history = predictor_model.fit(\n",
    "    all_train_data[:, :-3], \n",
    "    all_train_data[:, -3],\n",
    "    epochs=50,\n",
    "    verbose=2,\n",
    "    batch_size=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictor_model.predict(all_train_data[:, :-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(\n",
    "    np.hstack([results, \n",
    "               np.array(all_train_data[:, -3]).reshape(-1, 1),\n",
    "               np.array(all_train_data[:, -1]).reshape(-1, 1), \n",
    "               all_train_data_base['ordinal_date'].values.reshape(-1, 1)\n",
    "              ]))\n",
    "y.columns = ['predicted_count', 'actual_count', 'GEOID', 'ordinal_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_county_cases(result_array, date_string):\n",
    "    restricted_result_array = pd.DataFrame(\n",
    "        result_array.loc()[\n",
    "            date.fromisoformat(date_string).toordinal() == result_array.iloc()[:, 3],\n",
    "            :]).merge(county_indices).values\n",
    "    \n",
    "    central_lat = 37.5\n",
    "    central_lon = -96\n",
    "    extent = [-120, -70, 23, 50.5]\n",
    "    central_lon = np.mean(extent[:2])\n",
    "    central_lat = np.mean(extent[2:])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax = plt.axes(projection=ccrs.AlbersEqualArea(central_lon, central_lat))\n",
    "    ax.set_extent(extent)\n",
    "\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    ax.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.LAKES, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.BORDERS)\n",
    "    ax.add_feature(\n",
    "        cartopy.feature.ShapelyFeature(\n",
    "            [counties[int(restricted_result_array[int(i), -1])].geometry \n",
    "             for i in range(restricted_result_array.shape[0])], \n",
    "            cartopy.crs.PlateCarree(),\n",
    "            color='pink'))\n",
    "\n",
    "    ax.add_feature(cartopy.feature.STATES, edgecolor='lightgrey')\n",
    "    ax.add_feature(\n",
    "        cartopy.feature.ShapelyFeature(\n",
    "            [interstate.geometry for interstate in interstates],\n",
    "            cartopy.crs.PlateCarree(),\n",
    "            color='grey'))\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return image\n",
    "\n",
    "county_cases = [\n",
    "    plot_county_cases(y, image_date) \n",
    "    for image_date in np.unique(nytimes_data.date)[:-1]\n",
    "]\n",
    "\n",
    "mimwrite('./county_cases.gif', \n",
    "         county_cases,\n",
    "         fps=5,\n",
    "         subrectangles=True,\n",
    "         loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_county_counts(result_array, date_string):\n",
    "    restricted_result_array = pd.DataFrame(\n",
    "        result_array.loc()[\n",
    "            date.fromisoformat(date_string).toordinal() == result_array.iloc()[:, 3],\n",
    "            :]).merge(county_indices).values\n",
    "        \n",
    "    extent = [-125, -65, 23, 50.5]\n",
    "    central_lon = np.mean(extent[:2])\n",
    "    central_lat = np.mean(extent[2:])\n",
    "    \n",
    "    main_proj = cartopy.crs.PlateCarree()\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.add_subplot(projection=main_proj)\n",
    "    ax.set_extent(extent)\n",
    "    ax.set_aspect('auto')\n",
    "\n",
    "    ax.add_feature(cartopy.feature.OCEAN)\n",
    "    ax.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.LAKES, edgecolor='black')\n",
    "    ax.add_feature(cartopy.feature.BORDERS)\n",
    "\n",
    "    centroids = [\n",
    "        counties[int(restricted_result_array[int(i), -1])].\n",
    "        geometry.\n",
    "        centroid.\n",
    "        xy\n",
    "        for i in range(restricted_result_array.shape[0])]\n",
    "\n",
    "    for x, y in centroids:\n",
    "        ax.add_patch(patches.Circle(xy=[x[0], y[0]], \n",
    "                                    radius=0.2,                           \n",
    "                                    color='b', \n",
    "                                    alpha=0.3, \n",
    "                                    transform=main_proj))\n",
    "\n",
    "    ax.add_feature(cartopy.feature.STATES, edgecolor='lightgrey')\n",
    "            \n",
    "    ax.add_feature(\n",
    "        cartopy.feature.ShapelyFeature(\n",
    "            [interstate.geometry for interstate in interstates],\n",
    "            cartopy.crs.PlateCarree(),\n",
    "            color='grey'))            \n",
    "            \n",
    "    fig.canvas.draw()\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    return image\n",
    "\n",
    "county_counts = [\n",
    "    plot_county_counts(y, image_date) \n",
    "    for image_date in np.unique(nytimes_data.date)[:-1]\n",
    "]\n",
    "\n",
    "mimwrite('./county_counts.gif',\n",
    "         county_counts, \n",
    "         fps=5,\n",
    "         subrectangles=True,\n",
    "         loop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
